{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.6\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "def _get_weaviate_client_version():\n",
    "    pkg_name = \"weaviate-client\"\n",
    "    try:\n",
    "        return version(pkg_name)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "client_version = _get_weaviate_client_version()\n",
    "print(client_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import NaiveQaRagAgent\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def display_md(content):\n",
    "  display(Markdown(content))\n",
    "\n",
    "doc_uri = \"https://arxiv.org/html/2312.10997v5\"\n",
    "qa_agent = NaiveQaRagAgent(doc_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Naive RAG is the earliest methodology within the RAG research paradigm, developed shortly after the widespread adoption of ChatGPT. It follows a traditional process of indexing, retrieval, and generation, characterized as a \"Retrieve-Read\" framework. Naive RAG involves cleaning and extracting raw data in various formats, segmenting text into smaller chunks, encoding them into vector representations, and storing them in a vector database."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What is naive RAG?\"\n",
    "completion = qa_agent.query(question)\n",
    "display_md(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The authors of the paper are Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. They are affiliated with various institutions in Shanghai, including Tongji University, Fudan University, and Shanghai Research Institute for Intelligent Autonomous Systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# question = \"Who are the authors of this paper?\"\n",
    "# completion = qa_agent.query(question)\n",
    "# display_md(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Some benchmarks available for RAG include RGB, RECALL, and CRUD. These benchmarks focus on appraising essential abilities of RAG models. Tools like RAGAS, ARES, and TruLens employ LLMs to adjudicate quality scores."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# question = \"What are some benchmarks available for RAG?\"\n",
    "# completion = qa_agent.query(question)\n",
    "# display_md(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
